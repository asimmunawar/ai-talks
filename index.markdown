---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: page
title: Call for Papers
---

Neuro-symbolic AI (NSAI) is an interdisciplinary field that combines techniques from symbolic AI and neural network based models to create explainable AI systems capable of grounded logical reasoning over the large domain specific knowledge bases. However,  the recent emergence of foundation models or large language models (LLMs) trained on massive amounts of data has the potential to reshape NSAI. LLMs have made significant strides in various natural language processing (NLP) tasks, such as text generation, machine translation, question answering, and sentiment analysis. By harnessing the power of deep neural networks and extensive data, these models can identify patterns and generate coherent and contextually relevant text. Notably, NSAI models can potentially leverage these capabilities by utilizing symbolic manipulation as an intermediate step.

Several studies suggest that large language models, consisting of hundreds of billions of parameters, possess reasoning capabilities. However, it remains uncertain whether these models genuinely engage in abstract reasoning similar to humans or rely on specific shortcuts. In fact, approaches such as Chain-of-thought prompting techniques have been found to distort the rationales behind model predictions and LLMs have shown a limited grasp of symbolic meaning in coding tasks. Consequently, symbol manipulation serves as a fundamental tool for assessing the reasoning abilities of LLMs. Additionally, it is evident that neural systems are likely to be integrated with classical computers in various real-world applications, such as toolformer models. In such scenarios, the capacity to manipulate symbolic systems and generate valid statements within a grammar becomes crucial. Lastly, language models possess inherent limitations as world models due to the nature of their training data. Symbolic systems offer an inductive bias that could potentially compensate for these limitations.

Neural-symbolic approaches offer valuable solutions to address critical limitations, including the lack of interpretability and explainability, sensitivity to biases in training data, and challenges in reasoning about causality and temporal dependencies. Moreover, incorporating symbolic reasoning and cognitive processes into AI systems is becoming increasingly necessary to enhance their understanding and interpretation of complex real-world scenarios.

In the current landscape, NSAI approaches are more relevant than ever. They provide the tools to analyze and mitigate the limitations of current-generation LLMs, and we believe that NSAI can play a significant role as these models are deployed in real-world settings. Anticipating the widespread adoption of foundation models across industries, we predict that NSAI will gain further momentum in the coming years. However, it is essential for NSAI algorithms to evolve to effectively operate within the new AI paradigm of foundation models.


The primary objective of this workshop is to provide a dedicated platform for researchers to present and share their cutting-edge advancements in the next generation of NSAI. We anticipate that the workshop will serve as a catalyst for stimulating insightful discussions surrounding the challenges and opportunities within this field. By creating an environment conducive to knowledge exchange and the exploration of innovative ideas, we aim to foster collaboration and inspire new breakthroughs. We invite submissions on  topics and questions related to NSAI, including but not limited to:

- Survey of recent NSAI methods and applications
- How do we define NSAI? What role do they play in shaping the development of the next generation of large language models?
- To what extent and in what ways does NSAI contribute to natural language understanding and generation?
- Besides language-related tasks, what are the applications of NSAI in the era of LLMs for domains such as time series analysis, computer vision, robotics, etc.? 
- What role does NSAI play in grounding LLMs and enhancing their performance?
- Is it possible to leverage NSAI to achieve data efficiency? Can we train models using significantly less data while maintaining their performance?
- How can we effectively incorporate domain knowledge into the learning process within NSAI for LLMs?
- What strategies can we employ to address challenges related to compositional generalization using NSAI for LLMs?
- How can we combine symbolic reasoning and deep learning techniques to enhance knowledge representation and reasoning within LLMs?
- We also welcome submissions from researchers working on related topics such as neural program synthesis, program induction, and concept learning.

We look forward to your submissions and to seeing you at the workshop. If you have any questions, please feel free to contact the organizing committee.

---

## Format

Submissions should be in the form of a 4-page full paper or a 2-page abstract for posters/demonstrations. The papers should be formatted according to the conferenceâ€™s guidelines [https://neurips.cc/Conferences/2023/PaperInformation/StyleFiles](https://neurips.cc/Conferences/2023/PaperInformation/StyleFiles).

All accepted papers and extended abstracts will be presented as posters. The program committee will select a few papers for oral presentation. There will be a poster session during the scheduled coffee breaks to facilitate and spark discussions among attendees. Accepted papers will be made part of the workshop proceedings and published online on the workshop website.

We look forward to your submissions and to seeing you at the workshop. If you have any questions, please feel free to contact the organizing committee.

---

## Organizers

- Asim Munawar [website](https://research.ibm.com/people/asim-munawar), IBM Research, asim -*AT*- ibm -*-DoT-*- com (primary contact)
- Pranava Madhyastha [website](https://www.city.ac.uk/about/people/academics/pranava-madhyastha), City, University of London
- Ramon Fernandez Astudillo [website](https://mitibmwatsonailab.mit.edu/people/ramon-fernandez-astudillo/), IBM Research
- Abulhair Saparov [website](https://asaparov.org/), New York University
- Alessandra Russo [website](https://wp.doc.ic.ac.uk/arusso/), Imperial College London
